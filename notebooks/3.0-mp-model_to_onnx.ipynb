{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchvision is not available - cannot save figures\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "from speechbrain.pretrained import Tacotron2\n",
    "from speechbrain.pretrained import HIFIGAN\n",
    "\n",
    "import torch\n",
    "from torch.onnx import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_base_en = whisper.load_model(\"base.en\")\n",
    "whisper_base = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transcribe() missing 1 required positional argument: 'audio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m whisper_base_en\u001b[39m.\u001b[39;49mtranscribe()\n",
      "\u001b[0;31mTypeError\u001b[0m: transcribe() missing 1 required positional argument: 'audio'"
     ]
    }
   ],
   "source": [
    "whisper_base_en.transcribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated: output_names (1069226937.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    export(whisper_base, torch.zeros(1, 80, 1), f='transcribe', output_names=\"whisper_base_en.onnx\", verbose=True, input_names=[\"input\"], output_names=[\"output\"])\u001b[0m\n\u001b[0m                                                                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated: output_names\n"
     ]
    }
   ],
   "source": [
    "export(whisper_base, torch.zeros(1, 80, 1), 'transcribe', \"whisper_base_en.onnx\", verbose=True, input_names=[\"input\"], output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2 = Tacotron2.from_hparams(source=\"speechbrain/tts-tacotron2-ljspeech\", savedir=\"../tmpdir_tts\")\n",
    "hifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-ljspeech\", savedir=\"../tmpdir_vocoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/pretrained/interfaces.py:2649: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  \"text_sequences\": torch.tensor(\n",
      "/Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/utils/data_utils.py:416: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  return tensors[0].unsqueeze(0), torch.tensor([1.0])\n",
      "/Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/pretrained/interfaces.py:2661: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  input_lengths = torch.tensor(lens, device=self.device)\n",
      "/Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1544: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  max_len = torch.max(lengths).item()\n",
      "/Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1214: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.early_stopping and torch.sum(not_finished) == 0:\n",
      "/Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1216: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  if len(mel_outputs) == self.max_decoder_steps:\n",
      "/Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::PackPadded type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1666646991213/work/torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:4315: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n",
      "/Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::PadPacked type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1666646991213/work/torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/symbolic_helper.py:1457: UserWarning: ONNX export mode is set to TrainingMode.EVAL, but operator 'dropout' is set to train=True. Exporting with train=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch IR graph at exception: graph(%mods.model.embedding.weight : Float(148, 512, strides=[512, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.0.0.conv.weight : Float(512, 512, 5, strides=[2560, 5, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.0.0.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.0.1.weight : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.0.1.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.0.1.running_mean : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.0.1.running_var : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.0.1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.1.0.conv.weight : Float(512, 512, 5, strides=[2560, 5, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.1.0.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.1.1.weight : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.1.1.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.1.1.running_mean : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.1.1.running_var : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.1.1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.2.0.conv.weight : Float(512, 512, 5, strides=[2560, 5, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.2.0.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.2.1.weight : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.2.1.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.2.1.running_mean : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.2.1.running_var : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.convolutions.2.1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.lstm.weight_ih_l0 : Float(1024, 512, strides=[512, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.lstm.weight_hh_l0 : Float(1024, 256, strides=[256, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.lstm.bias_ih_l0 : Float(1024, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.lstm.bias_hh_l0 : Float(1024, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.lstm.weight_ih_l0_reverse : Float(1024, 512, strides=[512, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.lstm.weight_hh_l0_reverse : Float(1024, 256, strides=[256, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.lstm.bias_ih_l0_reverse : Float(1024, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.encoder.lstm.bias_hh_l0_reverse : Float(1024, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.prenet.layers.0.linear_layer.weight : Float(256, 80, strides=[80, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.prenet.layers.1.linear_layer.weight : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.attention_rnn.weight_ih : Float(4096, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.attention_rnn.weight_hh : Float(4096, 1024, strides=[1024, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.attention_rnn.bias_ih : Float(4096, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.attention_rnn.bias_hh : Float(4096, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.attention_layer.query_layer.linear_layer.weight : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.attention_layer.memory_layer.linear_layer.weight : Float(128, 512, strides=[512, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.attention_layer.v.linear_layer.weight : Float(1, 128, strides=[128, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.attention_layer.location_layer.location_conv.conv.weight : Float(32, 2, 31, strides=[62, 31, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.attention_layer.location_layer.location_dense.linear_layer.weight : Float(128, 32, strides=[32, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.decoder_rnn.weight_ih : Float(4096, 1536, strides=[1536, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.decoder_rnn.weight_hh : Float(4096, 1024, strides=[1024, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.decoder_rnn.bias_ih : Float(4096, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.decoder_rnn.bias_hh : Float(4096, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.linear_projection.linear_layer.weight : Float(80, 1536, strides=[1536, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.linear_projection.linear_layer.bias : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.gate_layer.linear_layer.weight : Float(1, 1536, strides=[1536, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.decoder.gate_layer.linear_layer.bias : Float(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.0.0.conv.weight : Float(512, 80, 5, strides=[400, 5, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.0.0.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.0.1.weight : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.0.1.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.0.1.running_mean : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.0.1.running_var : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.0.1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.1.0.conv.weight : Float(512, 512, 5, strides=[2560, 5, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.1.0.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.1.1.weight : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.1.1.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.1.1.running_mean : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.1.1.running_var : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.1.1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.2.0.conv.weight : Float(512, 512, 5, strides=[2560, 5, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.2.0.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.2.1.weight : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.2.1.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.2.1.running_mean : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.2.1.running_var : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.2.1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.3.0.conv.weight : Float(512, 512, 5, strides=[2560, 5, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.3.0.conv.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.3.1.weight : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.3.1.bias : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.3.1.running_mean : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.3.1.running_var : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.3.1.num_batches_tracked : Long(requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.4.0.conv.weight : Float(80, 512, 5, strides=[2560, 5, 1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.4.0.conv.bias : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.4.1.weight : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.4.1.bias : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.4.1.running_mean : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.4.1.running_var : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
      "      %mods.model.postnet.convolutions.4.1.num_batches_tracked : Long(requires_grad=0, device=cpu)):\n",
      "  %29188 : Long(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = prim::Constant[value= 56  57  55  46  51  44 [ CPULongType{1,6} ]]()\n",
      "  %30783 : Long(device=cpu) = prim::Constant[value={-1}](), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.sparse.Embedding::embedding\n",
      "  %30784 : Bool(device=cpu) = prim::Constant[value={0}](), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.sparse.Embedding::embedding\n",
      "  %20212 : Float(1, 6, 512, strides=[3072, 512, 1], requires_grad=0, device=cpu) = aten::embedding(%mods.model.embedding.weight, %29188, %30783, %30784, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.sparse.Embedding::embedding # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:2194:0\n",
      "  %30785 : Long(device=cpu) = prim::Constant[value={1}](), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %30786 : Long(device=cpu) = prim::Constant[value={2}](), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %embedded_inputs : Float(1, 512, 6, strides=[3072, 1, 512], requires_grad=0, device=cpu) = aten::transpose(%20212, %30785, %30786), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1511:0\n",
      "  %30787 : Long(device=cpu) = prim::Constant[value={6}](), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %30788 : Long(device=cpu) = prim::Constant[value={0}](), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20218 : Device = prim::Constant[value=\"cpu\"](), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:663:0\n",
      "  %20219 : NoneType = prim::Constant(), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %input.3 : Float(1, 512, 6, strides=[3072, 1, 512], requires_grad=0, device=cpu) = aten::to(%embedded_inputs, %30787, %30788, %20218, %20219, %30784, %30784, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:663:0\n",
      "  %29191 : int[] = prim::Constant[value=[1]]()\n",
      "  %29192 : int[] = prim::Constant[value=[2]]()\n",
      "  %29194 : int[] = prim::Constant[value=[0]]()\n",
      "  %30789 : Bool(device=cpu) = prim::Constant[value={1}](), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.container.Sequential::convolutions.0/speechbrain.lobes.models.Tacotron2.ConvNorm::convolutions.0.0/torch.nn.modules.conv.Conv1d::conv\n",
      "  %input.5 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.3, %mods.model.encoder.convolutions.0.0.conv.weight, %mods.model.encoder.convolutions.0.0.conv.bias, %29191, %29192, %29191, %30784, %29194, %30785, %30784, %30784, %30789, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.container.Sequential::convolutions.0/speechbrain.lobes.models.Tacotron2.ConvNorm::convolutions.0.0/torch.nn.modules.conv.Conv1d::conv # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/conv.py:308:0\n",
      "  %30790 : Double(device=cpu) = prim::Constant[value={0.1}](), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.container.Sequential::convolutions.0/torch.nn.modules.batchnorm.BatchNorm1d::convolutions.0.1\n",
      "  %30791 : Double(device=cpu) = prim::Constant[value={1e-05}](), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.container.Sequential::convolutions.0/torch.nn.modules.batchnorm.BatchNorm1d::convolutions.0.1\n",
      "  %20243 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.5, %mods.model.encoder.convolutions.0.1.weight, %mods.model.encoder.convolutions.0.1.bias, %mods.model.encoder.convolutions.0.1.running_mean, %mods.model.encoder.convolutions.0.1.running_var, %30784, %30790, %30791, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.container.Sequential::convolutions.0/torch.nn.modules.batchnorm.BatchNorm1d::convolutions.0.1 # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:2435:0\n",
      "  %20244 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::relu(%20243), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %30792 : Double(device=cpu) = prim::Constant[value={0.5}](), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20247 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::dropout(%20244, %30792, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1250:0\n",
      "  %input.7 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::to(%20247, %30787, %30788, %20218, %20219, %30784, %30784, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:663:0\n",
      "  %input.9 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.7, %mods.model.encoder.convolutions.1.0.conv.weight, %mods.model.encoder.convolutions.1.0.conv.bias, %29191, %29192, %29191, %30784, %29194, %30785, %30784, %30784, %30789, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.container.Sequential::convolutions.1/speechbrain.lobes.models.Tacotron2.ConvNorm::convolutions.1.0/torch.nn.modules.conv.Conv1d::conv # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/conv.py:308:0\n",
      "  %20275 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.9, %mods.model.encoder.convolutions.1.1.weight, %mods.model.encoder.convolutions.1.1.bias, %mods.model.encoder.convolutions.1.1.running_mean, %mods.model.encoder.convolutions.1.1.running_var, %30784, %30790, %30791, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.container.Sequential::convolutions.1/torch.nn.modules.batchnorm.BatchNorm1d::convolutions.1.1 # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:2435:0\n",
      "  %20276 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::relu(%20275), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %20279 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::dropout(%20276, %30792, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1250:0\n",
      "  %input.11 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::to(%20279, %30787, %30788, %20218, %20219, %30784, %30784, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:663:0\n",
      "  %input.13 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.11, %mods.model.encoder.convolutions.2.0.conv.weight, %mods.model.encoder.convolutions.2.0.conv.bias, %29191, %29192, %29191, %30784, %29194, %30785, %30784, %30784, %30789, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.container.Sequential::convolutions.2/speechbrain.lobes.models.Tacotron2.ConvNorm::convolutions.2.0/torch.nn.modules.conv.Conv1d::conv # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/conv.py:308:0\n",
      "  %20307 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::batch_norm(%input.13, %mods.model.encoder.convolutions.2.1.weight, %mods.model.encoder.convolutions.2.1.bias, %mods.model.encoder.convolutions.2.1.running_mean, %mods.model.encoder.convolutions.2.1.running_var, %30784, %30790, %30791, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.container.Sequential::convolutions.2/torch.nn.modules.batchnorm.BatchNorm1d::convolutions.2.1 # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:2435:0\n",
      "  %20308 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::relu(%20307), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %20311 : Float(1, 512, 6, strides=[3072, 6, 1], requires_grad=0, device=cpu) = aten::dropout(%20308, %30792, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1250:0\n",
      "  %x : Float(1, 6, 512, strides=[3072, 1, 6], requires_grad=0, device=cpu) = aten::transpose(%20311, %30785, %30786), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:663:0\n",
      "  %29204 : Long(1, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n",
      "  %input.15 : Float(6, 512, strides=[512, 1], requires_grad=0, device=cpu), %batch_sizes : Long(6, strides=[1], requires_grad=0, device=cpu) = aten::_pack_padded_sequence(%x, %29204, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/utils/rnn.py:256:0\n",
      "  %29205 : int[] = prim::Constant[value=[2, 1, 256]]()\n",
      "  %20343 : Float(2, 1, 256, strides=[256, 256, 1], requires_grad=0, device=cpu) = aten::zeros(%29205, %30787, %20219, %20218, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTM::lstm # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:740:0\n",
      "  %20352 : Float(2, 1, 256, strides=[256, 256, 1], requires_grad=0, device=cpu) = aten::zeros(%29205, %30787, %20219, %20218, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTM::lstm # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:740:0\n",
      "  %20394 : Tensor[] = prim::ListConstruct(%20343, %20352), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTM::lstm\n",
      "  %20395 : Tensor[] = prim::ListConstruct(%mods.model.encoder.lstm.weight_ih_l0, %mods.model.encoder.lstm.weight_hh_l0, %mods.model.encoder.lstm.bias_ih_l0, %mods.model.encoder.lstm.bias_hh_l0, %mods.model.encoder.lstm.weight_ih_l0_reverse, %mods.model.encoder.lstm.weight_hh_l0_reverse, %mods.model.encoder.lstm.bias_ih_l0_reverse, %mods.model.encoder.lstm.bias_hh_l0_reverse), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTM::lstm\n",
      "  %30793 : Double(device=cpu) = prim::Constant[value={0}](), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTM::lstm\n",
      "  %20401 : Float(6, 512, strides=[512, 1], requires_grad=0, device=cpu), %20402 : Float(2, 1, 256, strides=[256, 256, 1], requires_grad=0, device=cpu), %20403 : Float(2, 1, 256, strides=[256, 256, 1], requires_grad=0, device=cpu) = aten::lstm(%input.15, %batch_sizes, %20394, %20395, %30789, %30785, %30793, %30784, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTM::lstm # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:757:0\n",
      "  %20405 : Long(device=cpu) = aten::size(%batch_sizes, %30788), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/utils/rnn.py:323:0\n",
      "  %memory : Float(1, 6, 512, strides=[512, 512, 1], requires_grad=0, device=cpu), %20411 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::_pad_packed_sequence(%20401, %batch_sizes, %30789, %30793, %20405), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/utils/rnn.py:329:0\n",
      "  %20413 : Long(device=cpu) = aten::size(%memory, %30788), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:797:0\n",
      "  %30794 : Long(device=cpu) = prim::Constant[value={80}](), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20417 : int[] = prim::ListConstruct(%20413, %30794), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20422 : Float(1, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::zeros(%20417, %30787, %20219, %20218, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:800:0\n",
      "  %29211 : Bool(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = prim::Constant[value= 0  0  0  0  0  0 [ CPUBoolType{1,6} ]]()\n",
      "  %20452 : Long(device=cpu) = aten::size(%memory, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:835:0\n",
      "  %30795 : Long(device=cpu) = prim::Constant[value={1024}](), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20457 : int[] = prim::ListConstruct(%20413, %30795), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20462 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::zeros(%20457, %30787, %20219, %20218, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:837:0\n",
      "  %20484 : int[] = prim::ListConstruct(%20413, %20452), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %attention_weights.1 : Float(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = aten::zeros(%20484, %30787, %20219, %20218, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:844:0\n",
      "  %attention_weights_cum.1 : Float(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = aten::zeros(%20484, %30787, %20219, %20218, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:847:0\n",
      "  %30796 : Long(device=cpu) = prim::Constant[value={512}](), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20497 : int[] = prim::ListConstruct(%20413, %30796), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %attention_context.1 : Float(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::zeros(%20497, %30787, %20219, %20218, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:848:0\n",
      "  %processed_memory : Float(1, 6, 128, strides=[768, 128, 1], requires_grad=0, device=cpu) = aten::linear(%memory, %mods.model.decoder.attention_layer.memory_layer.linear_layer.weight, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.LinearNorm::memory_layer/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %20509 : int[] = prim::ListConstruct(%20413), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %30797 : Long(device=cpu) = prim::Constant[value={3}](), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20514 : Int(1, strides=[1], requires_grad=0, device=cpu) = aten::zeros(%20509, %30797, %20219, %20218, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1148:0\n",
      "  %20524 : Int(1, strides=[1], requires_grad=0, device=cpu) = aten::ones(%20509, %30797, %20219, %20218, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1156:0\n",
      "  %20547 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::linear(%20422, %mods.model.decoder.prenet.layers.0.linear_layer.weight, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Prenet::prenet/speechbrain.lobes.models.Tacotron2.LinearNorm::layers.0/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %20548 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::relu(%20547), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Prenet::prenet # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %20551 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::dropout(%20548, %30792, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Prenet::prenet # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1250:0\n",
      "  %20553 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::linear(%20551, %mods.model.decoder.prenet.layers.1.linear_layer.weight, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Prenet::prenet/speechbrain.lobes.models.Tacotron2.LinearNorm::layers.1/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %20554 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::relu(%20553), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Prenet::prenet # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %decoder_input.1 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::dropout(%20554, %30792, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Prenet::prenet # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1250:0\n",
      "  %20558 : Tensor[] = prim::ListConstruct(%decoder_input.1, %attention_context.1), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20560 : Float(1, 768, strides=[768, 1], requires_grad=0, device=cpu) = aten::cat(%20558, %30783), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:987:0\n",
      "  %20561 : Float(1, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::linear(%20462, %mods.model.decoder.attention_rnn.weight_hh, %mods.model.decoder.attention_rnn.bias_hh), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20562 : Float(1, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::linear(%20560, %mods.model.decoder.attention_rnn.weight_ih, %mods.model.decoder.attention_rnn.bias_ih), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29434 : Tensor = aten::type_as(%20562, %20561)\n",
      "  %29733 : Float(1, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::add(%20561, %29434, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %30798 : Long(device=cpu) = prim::Constant[value={4}](), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn\n",
      "  %30383 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu), %30384 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu), %30385 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu), %30386 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::unsafe_chunk[_outputs=4](%29733, %30798, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29734 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::sigmoid(%30383), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29735 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::sigmoid(%30384), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29736 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::tanh(%30385), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29737 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::sigmoid(%30386), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20576 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::mul(%29735, %20462), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20577 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::mul(%29734, %29736), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29435 : Tensor = aten::type_as(%20577, %20576)\n",
      "  %29738 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::add(%20576, %29435, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20580 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::tanh(%29738), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %attention_hidden.1 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::mul(%29737, %20580), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %attention_hidden_state.1 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::dropout(%attention_hidden.1, %30790, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1250:0\n",
      "  %20589 : Float(1, 1, 6, strides=[6, 6, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%attention_weights.1, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:989:0\n",
      "  %20591 : Float(1, 1, 6, strides=[6, 6, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%attention_weights_cum.1, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:992:0\n",
      "  %20592 : Tensor[] = prim::ListConstruct(%20589, %20591), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %input.17 : Float(1, 2, 6, strides=[12, 6, 1], requires_grad=0, device=cpu) = aten::cat(%20592, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:993:0\n",
      "  %20596 : Float(1, 1, 1024, strides=[1024, 1024, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%attention_hidden_state.1, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:333:0\n",
      "  %20598 : Float(1, 1, 128, strides=[128, 128, 1], requires_grad=0, device=cpu) = aten::linear(%20596, %mods.model.decoder.attention_layer.query_layer.linear_layer.weight, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer/speechbrain.lobes.models.Tacotron2.LinearNorm::query_layer/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %29213 : int[] = prim::Constant[value=[15]]()\n",
      "  %20614 : Float(1, 32, 6, strides=[192, 6, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.17, %mods.model.decoder.attention_layer.location_layer.location_conv.conv.weight, %20219, %29191, %29213, %29191, %30784, %29194, %30785, %30784, %30784, %30789, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer/speechbrain.lobes.models.Tacotron2.LocationLayer::location_layer/speechbrain.lobes.models.Tacotron2.ConvNorm::location_conv/torch.nn.modules.conv.Conv1d::conv # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/conv.py:308:0\n",
      "  %20617 : Float(1, 6, 32, strides=[192, 1, 6], requires_grad=0, device=cpu) = aten::transpose(%20614, %30785, %30786), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer/speechbrain.lobes.models.Tacotron2.LocationLayer::location_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:244:0\n",
      "  %20619 : Float(1, 6, 128, strides=[768, 128, 1], requires_grad=0, device=cpu) = aten::linear(%20617, %mods.model.decoder.attention_layer.location_layer.location_dense.linear_layer.weight, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer/speechbrain.lobes.models.Tacotron2.LocationLayer::location_layer/speechbrain.lobes.models.Tacotron2.LinearNorm::location_dense/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %20621 : Float(1, 6, 128, strides=[768, 128, 1], requires_grad=0, device=cpu) = aten::add(%20598, %20619, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:334:0\n",
      "  %20623 : Float(1, 6, 128, strides=[768, 128, 1], requires_grad=0, device=cpu) = aten::add(%20621, %processed_memory, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:334:0\n",
      "  %20624 : Float(1, 6, 128, strides=[768, 128, 1], requires_grad=0, device=cpu) = aten::tanh(%20623), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:334:0\n",
      "  %20626 : Float(1, 6, 1, strides=[6, 1, 1], requires_grad=0, device=cpu) = aten::linear(%20624, %mods.model.decoder.attention_layer.v.linear_layer.weight, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer/speechbrain.lobes.models.Tacotron2.LinearNorm::v/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %20628 : Float(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = aten::squeeze(%20626, %30786), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:335:0\n",
      "  %30799 : Double(device=cpu) = prim::Constant[value={-inf}](), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer\n",
      "  %alignment.1 : Float(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = aten::masked_fill(%20628, %29211, %30799), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:372:0\n",
      "  %attention_weights.3 : Float(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = aten::softmax(%alignment.1, %30785, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1838:0\n",
      "  %20635 : Float(1, 1, 6, strides=[6, 6, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%attention_weights.3, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:376:0\n",
      "  %20636 : Float(1, 1, 512, strides=[512, 512, 1], requires_grad=0, device=cpu) = aten::bmm(%20635, %memory), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:378:0\n",
      "  %attention_context.3 : Float(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::squeeze(%20636, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:378:0\n",
      "  %29436 : Tensor = aten::type_as(%attention_weights.3, %attention_weights_cum.1)\n",
      "  %29739 : Float(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = aten::add(%attention_weights_cum.1, %29436, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:996:0\n",
      "  %20644 : Tensor[] = prim::ListConstruct(%attention_hidden_state.1, %attention_context.3), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20646 : Float(1, 1536, strides=[1536, 1], requires_grad=0, device=cpu) = aten::cat(%20644, %30783), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:998:0\n",
      "  %20647 : Float(1, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::linear(%20462, %mods.model.decoder.decoder_rnn.weight_hh, %mods.model.decoder.decoder_rnn.bias_hh), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20648 : Float(1, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::linear(%20646, %mods.model.decoder.decoder_rnn.weight_ih, %mods.model.decoder.decoder_rnn.bias_ih), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29437 : Tensor = aten::type_as(%20648, %20647)\n",
      "  %29740 : Float(1, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::add(%20647, %29437, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %30387 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu), %30388 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu), %30389 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu), %30390 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::unsafe_chunk[_outputs=4](%29740, %30798, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29741 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::sigmoid(%30387), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29742 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::sigmoid(%30388), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29743 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::tanh(%30389), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29744 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::sigmoid(%30390), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20662 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::mul(%29742, %20462), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20663 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::mul(%29741, %29743), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29438 : Tensor = aten::type_as(%20663, %20662)\n",
      "  %29745 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::add(%20662, %29438, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20666 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::tanh(%29745), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %decoder_hidden.1 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::mul(%29744, %20666), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20673 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::dropout(%decoder_hidden.1, %30790, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1250:0\n",
      "  %20674 : Tensor[] = prim::ListConstruct(%20673, %attention_context.3), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20676 : Float(1, 1536, strides=[1536, 1], requires_grad=0, device=cpu) = aten::cat(%20674, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1005:0\n",
      "  %20677 : Float(1, 80, strides=[80, 1], requires_grad=0, device=cpu) = aten::linear(%20676, %mods.model.decoder.linear_projection.linear_layer.weight, %mods.model.decoder.linear_projection.linear_layer.bias), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.LinearNorm::linear_projection/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %20678 : Float(1, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::linear(%20676, %mods.model.decoder.gate_layer.linear_layer.weight, %mods.model.decoder.gate_layer.linear_layer.bias), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.LinearNorm::gate_layer/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %mel_outputs.1 : Float(1, 1, 80, strides=[80, 80, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%20677, %30788), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1163:0\n",
      "  %20681 : Float(1, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::sigmoid(%20678), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1169:0\n",
      "  %20683 : Bool(1, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::le(%20681, %30792), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1180:0\n",
      "  %20688 : Int(1, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::to(%20683, %30797, %30784, %30784, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1181:0\n",
      "  %20690 : Int(1, strides=[1], requires_grad=0, device=cpu) = aten::squeeze(%20688, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1183:0\n",
      "  %20691 : Int(1, strides=[1], requires_grad=0, device=cpu) = aten::mul(%20524, %20690), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1185:0\n",
      "  %29439 : Tensor = aten::type_as(%20691, %20514)\n",
      "  %29746 : Int(1, strides=[1], requires_grad=0, device=cpu) = aten::add(%20514, %29439, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:1187:0\n",
      "  %20708 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::linear(%20677, %mods.model.decoder.prenet.layers.0.linear_layer.weight, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Prenet::prenet/speechbrain.lobes.models.Tacotron2.LinearNorm::layers.0/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %20709 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::relu(%20708), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Prenet::prenet # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %20712 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::dropout(%20709, %30792, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Prenet::prenet # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1250:0\n",
      "  %20714 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::linear(%20712, %mods.model.decoder.prenet.layers.1.linear_layer.weight, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Prenet::prenet/speechbrain.lobes.models.Tacotron2.LinearNorm::layers.1/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %20715 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::relu(%20714), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Prenet::prenet # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %decoder_input.3 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::dropout(%20715, %30792, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Prenet::prenet # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1250:0\n",
      "  %20719 : Tensor[] = prim::ListConstruct(%decoder_input.3, %attention_context.3), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20721 : Float(1, 768, strides=[768, 1], requires_grad=0, device=cpu) = aten::cat(%20719, %30783), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:987:0\n",
      "  %20722 : Float(1, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::linear(%attention_hidden_state.1, %mods.model.decoder.attention_rnn.weight_hh, %mods.model.decoder.attention_rnn.bias_hh), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20723 : Float(1, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::linear(%20721, %mods.model.decoder.attention_rnn.weight_ih, %mods.model.decoder.attention_rnn.bias_ih), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29440 : Tensor = aten::type_as(%20723, %20722)\n",
      "  %29747 : Float(1, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::add(%20722, %29440, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %30391 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu), %30392 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu), %30393 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu), %30394 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::unsafe_chunk[_outputs=4](%29747, %30798, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29748 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::sigmoid(%30391), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29749 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::sigmoid(%30392), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29750 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::tanh(%30393), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29751 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu) = aten::sigmoid(%30394), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20737 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::mul(%29749, %29738), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20738 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::mul(%29748, %29750), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29441 : Tensor = aten::type_as(%20738, %20737)\n",
      "  %29752 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::add(%20737, %29441, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20741 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::tanh(%29752), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %attention_hidden.3 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::mul(%29751, %20741), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::attention_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %attention_hidden_state.3 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = aten::dropout(%attention_hidden.3, %30790, %30784), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1250:0\n",
      "  %20752 : Float(1, 1, 6, strides=[6, 6, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%29739, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:992:0\n",
      "  %20753 : Tensor[] = prim::ListConstruct(%20635, %20752), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %input.19 : Float(1, 2, 6, strides=[12, 6, 1], requires_grad=0, device=cpu) = aten::cat(%20753, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:993:0\n",
      "  %20757 : Float(1, 1, 1024, strides=[1024, 1024, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%attention_hidden_state.3, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:333:0\n",
      "  %20759 : Float(1, 1, 128, strides=[128, 128, 1], requires_grad=0, device=cpu) = aten::linear(%20757, %mods.model.decoder.attention_layer.query_layer.linear_layer.weight, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer/speechbrain.lobes.models.Tacotron2.LinearNorm::query_layer/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %20775 : Float(1, 32, 6, strides=[192, 6, 1], requires_grad=0, device=cpu) = aten::_convolution(%input.19, %mods.model.decoder.attention_layer.location_layer.location_conv.conv.weight, %20219, %29191, %29213, %29191, %30784, %29194, %30785, %30784, %30784, %30789, %30789), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer/speechbrain.lobes.models.Tacotron2.LocationLayer::location_layer/speechbrain.lobes.models.Tacotron2.ConvNorm::location_conv/torch.nn.modules.conv.Conv1d::conv # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/conv.py:308:0\n",
      "  %20778 : Float(1, 6, 32, strides=[192, 1, 6], requires_grad=0, device=cpu) = aten::transpose(%20775, %30785, %30786), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer/speechbrain.lobes.models.Tacotron2.LocationLayer::location_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:244:0\n",
      "  %20780 : Float(1, 6, 128, strides=[768, 128, 1], requires_grad=0, device=cpu) = aten::linear(%20778, %mods.model.decoder.attention_layer.location_layer.location_dense.linear_layer.weight, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer/speechbrain.lobes.models.Tacotron2.LocationLayer::location_layer/speechbrain.lobes.models.Tacotron2.LinearNorm::location_dense/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %20782 : Float(1, 6, 128, strides=[768, 128, 1], requires_grad=0, device=cpu) = aten::add(%20759, %20780, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:334:0\n",
      "  %20784 : Float(1, 6, 128, strides=[768, 128, 1], requires_grad=0, device=cpu) = aten::add(%20782, %processed_memory, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:334:0\n",
      "  %20785 : Float(1, 6, 128, strides=[768, 128, 1], requires_grad=0, device=cpu) = aten::tanh(%20784), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:334:0\n",
      "  %20787 : Float(1, 6, 1, strides=[6, 1, 1], requires_grad=0, device=cpu) = aten::linear(%20785, %mods.model.decoder.attention_layer.v.linear_layer.weight, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer/speechbrain.lobes.models.Tacotron2.LinearNorm::v/torch.nn.modules.linear.Linear::linear_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %20789 : Float(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = aten::squeeze(%20787, %30786), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:335:0\n",
      "  %alignment.3 : Float(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = aten::masked_fill(%20789, %29211, %30799), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:372:0\n",
      "  %attention_weights.5 : Float(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = aten::softmax(%alignment.3, %30785, %20219), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/functional.py:1838:0\n",
      "  %20796 : Float(1, 1, 6, strides=[6, 6, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%attention_weights.5, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:376:0\n",
      "  %20797 : Float(1, 1, 512, strides=[512, 512, 1], requires_grad=0, device=cpu) = aten::bmm(%20796, %memory), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:378:0\n",
      "  %attention_context.5 : Float(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::squeeze(%20797, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/speechbrain.lobes.models.Tacotron2.Attention::attention_layer # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:378:0\n",
      "  %29442 : Tensor = aten::type_as(%attention_weights.5, %29739)\n",
      "  %attention_weights_cum.5 : Float(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = aten::add_(%29739, %29442, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:996:0\n",
      "  %20805 : Tensor[] = prim::ListConstruct(%attention_hidden_state.3, %attention_context.5), scope: speechbrain.pretrained.interfaces.Tacotron2::\n",
      "  %20807 : Float(1, 1536, strides=[1536, 1], requires_grad=0, device=cpu) = aten::cat(%20805, %30783), scope: speechbrain.pretrained.interfaces.Tacotron2:: # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/speechbrain/lobes/models/Tacotron2.py:998:0\n",
      "  %20808 : Float(1, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::linear(%20673, %mods.model.decoder.decoder_rnn.weight_hh, %mods.model.decoder.decoder_rnn.bias_hh), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %20809 : Float(1, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::linear(%20807, %mods.model.decoder.decoder_rnn.weight_ih, %mods.model.decoder.decoder_rnn.bias_ih), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %29443 : Tensor = aten::type_as(%20809, %20808)\n",
      "  %29753 : Float(1, 4096, strides=[4096, 1], requires_grad=0, device=cpu) = aten::add(%20808, %29443, %30785), scope: speechbrain.pretrained.interfaces.Tacotron2::/torch.nn.modules.rnn.LSTMCell::decoder_rnn # /Users/moritz/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189:0\n",
      "  %30395 : Float(1, 1024, strides=[4096, 1], requires_grad=0, device=cpu), %30396 : Float(1, 10"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOnnxExporterError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/utils.py:1115\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1115\u001b[0m     graph \u001b[39m=\u001b[39m _optimize_graph(\n\u001b[1;32m   1116\u001b[0m         graph,\n\u001b[1;32m   1117\u001b[0m         operator_export_type,\n\u001b[1;32m   1118\u001b[0m         _disable_torch_constant_prop\u001b[39m=\u001b[39;49m_disable_torch_constant_prop,\n\u001b[1;32m   1119\u001b[0m         fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m   1120\u001b[0m         params_dict\u001b[39m=\u001b[39;49mparams_dict,\n\u001b[1;32m   1121\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m   1122\u001b[0m         input_names\u001b[39m=\u001b[39;49minput_names,\n\u001b[1;32m   1123\u001b[0m         module\u001b[39m=\u001b[39;49mmodule,\n\u001b[1;32m   1124\u001b[0m     )\n\u001b[1;32m   1125\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/utils.py:663\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    661\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m--> 663\u001b[0m graph \u001b[39m=\u001b[39m _C\u001b[39m.\u001b[39;49m_jit_pass_onnx(graph, operator_export_type)\n\u001b[1;32m    664\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/utils.py:1867\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(graph, block, node, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m   1864\u001b[0m         attrs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1865\u001b[0m             k: symbolic_helper\u001b[39m.\u001b[39m_node_get(node, k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mattributeNames()\n\u001b[1;32m   1866\u001b[0m         }\n\u001b[0;32m-> 1867\u001b[0m         \u001b[39mreturn\u001b[39;00m symbolic_fn(graph_context, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mattrs)\n\u001b[1;32m   1869\u001b[0m attrs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1870\u001b[0m     k \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39mkindOf(k)[\u001b[39m0\u001b[39m]: symbolic_helper\u001b[39m.\u001b[39m_node_get(node, k)\n\u001b[1;32m   1871\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mattributeNames()\n\u001b[1;32m   1872\u001b[0m }\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/symbolic_helper.py:303\u001b[0m, in \u001b[0;36mparse_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(g, *args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_outputs\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs, (\n\u001b[1;32m    299\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSymbolic function \u001b[39m\u001b[39m{\u001b[39;00mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39ms \u001b[39m\u001b[39m'\u001b[39m\u001b[39m**kwargs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m can only contain \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_outputs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m key at \u001b[39m\u001b[39m'\u001b[39m\u001b[39m**kwargs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mFILE_BUG_MSG\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m     )\n\u001b[0;32m--> 303\u001b[0m \u001b[39mreturn\u001b[39;00m fn(g, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/symbolic_opset13.py:477\u001b[0m, in \u001b[0;36munsafe_chunk\u001b[0;34m(g, self, chunks, dim, _outputs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m     \u001b[39mreturn\u001b[39;00m symbolic_helper\u001b[39m.\u001b[39;49m_unimplemented(\u001b[39m\"\u001b[39;49m\u001b[39munsafe_chunk\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39munknown dimension size\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    478\u001b[0m split_size \u001b[39m=\u001b[39m (size \u001b[39m+\u001b[39m chunks \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m chunks\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/symbolic_helper.py:577\u001b[0m, in \u001b[0;36m_unimplemented\u001b[0;34m(op, msg, value)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m GLOBALS\u001b[39m.\u001b[39moperator_export_type \u001b[39m==\u001b[39m _C_onnx\u001b[39m.\u001b[39mOperatorExportTypes\u001b[39m.\u001b[39mONNX:\n\u001b[0;32m--> 577\u001b[0m     _onnx_unsupported(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mop\u001b[39m}\u001b[39;49;00m\u001b[39m, \u001b[39;49m\u001b[39m{\u001b[39;49;00mmsg\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, value)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/symbolic_helper.py:592\u001b[0m, in \u001b[0;36m_onnx_unsupported\u001b[0;34m(op_name, value)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mSymbolicValueError(\n\u001b[1;32m    589\u001b[0m         message,\n\u001b[1;32m    590\u001b[0m         value,\n\u001b[1;32m    591\u001b[0m     )\n\u001b[0;32m--> 592\u001b[0m \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mOnnxExporterError(message)\n",
      "\u001b[0;31mOnnxExporterError\u001b[0m: Unsupported: ONNX export of operator unsafe_chunk, unknown dimension size. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m export(tacotron2, [\u001b[39m\"\u001b[39;49m\u001b[39mstring\u001b[39;49m\u001b[39m\"\u001b[39;49m],\u001b[39m'\u001b[39;49m\u001b[39mtacotron2\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtacotron2.onnx\u001b[39;49m\u001b[39m\"\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, input_names\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m], output_names\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39moutput\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/utils.py:504\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39m@_beartype\u001b[39m\u001b[39m.\u001b[39mbeartype\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(\n\u001b[1;32m    188\u001b[0m     model: Union[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m     export_modules_as_functions: Union[\u001b[39mbool\u001b[39m, Collection[Type[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule]]] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    205\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m \u001b[39m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 504\u001b[0m     _export(\n\u001b[1;32m    505\u001b[0m         model,\n\u001b[1;32m    506\u001b[0m         args,\n\u001b[1;32m    507\u001b[0m         f,\n\u001b[1;32m    508\u001b[0m         export_params,\n\u001b[1;32m    509\u001b[0m         verbose,\n\u001b[1;32m    510\u001b[0m         training,\n\u001b[1;32m    511\u001b[0m         input_names,\n\u001b[1;32m    512\u001b[0m         output_names,\n\u001b[1;32m    513\u001b[0m         operator_export_type\u001b[39m=\u001b[39;49moperator_export_type,\n\u001b[1;32m    514\u001b[0m         opset_version\u001b[39m=\u001b[39;49mopset_version,\n\u001b[1;32m    515\u001b[0m         do_constant_folding\u001b[39m=\u001b[39;49mdo_constant_folding,\n\u001b[1;32m    516\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m    517\u001b[0m         keep_initializers_as_inputs\u001b[39m=\u001b[39;49mkeep_initializers_as_inputs,\n\u001b[1;32m    518\u001b[0m         custom_opsets\u001b[39m=\u001b[39;49mcustom_opsets,\n\u001b[1;32m    519\u001b[0m         export_modules_as_functions\u001b[39m=\u001b[39;49mexport_modules_as_functions,\n\u001b[1;32m    520\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/utils.py:1529\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1526\u001b[0m     dynamic_axes \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1527\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1529\u001b[0m graph, params_dict, torch_out \u001b[39m=\u001b[39m _model_to_graph(\n\u001b[1;32m   1530\u001b[0m     model,\n\u001b[1;32m   1531\u001b[0m     args,\n\u001b[1;32m   1532\u001b[0m     verbose,\n\u001b[1;32m   1533\u001b[0m     input_names,\n\u001b[1;32m   1534\u001b[0m     output_names,\n\u001b[1;32m   1535\u001b[0m     operator_export_type,\n\u001b[1;32m   1536\u001b[0m     val_do_constant_folding,\n\u001b[1;32m   1537\u001b[0m     fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m   1538\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m   1539\u001b[0m     dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m   1540\u001b[0m )\n\u001b[1;32m   1542\u001b[0m \u001b[39m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1543\u001b[0m defer_weight_export \u001b[39m=\u001b[39m (\n\u001b[1;32m   1544\u001b[0m     export_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _exporter_states\u001b[39m.\u001b[39mExportTypes\u001b[39m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1545\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openai/lib/python3.10/site-packages/torch/onnx/utils.py:1126\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     graph \u001b[39m=\u001b[39m _optimize_graph(\n\u001b[1;32m   1116\u001b[0m         graph,\n\u001b[1;32m   1117\u001b[0m         operator_export_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1123\u001b[0m         module\u001b[39m=\u001b[39mmodule,\n\u001b[1;32m   1124\u001b[0m     )\n\u001b[1;32m   1125\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1126\u001b[0m     torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mlog(\u001b[39m\"\u001b[39;49m\u001b[39mTorch IR graph at exception: \u001b[39;49m\u001b[39m\"\u001b[39;49m, graph)\n\u001b[1;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m is_script \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(model, (torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptFunction, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptModule))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "export(tacotron2, [\"string\"], 'tacotron2', \"tacotron2.onnx\", verbose=True, input_names=[\"input\"], output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export(hifi_gan, torch.zeros((80,1)), 'hifi_gan', \"hifi_gan.onnx\", verbose=True, input_names=[\"input\"], output_names=[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 08:09:04) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "505538a42fd46471b9db6090de5ab2796e3d9fdf6fd273705b5951e86929a9f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
