{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center>A first end-to-end prototype using the computer's sounddevice</h1>\n",
    "\n",
    "<h2> Description </h2>\n",
    "This notebook is self-contained, you do not need the model server to run. \n",
    "\n",
    "The notebook contains a first end-to-end prototype of the speech-to-speech translation agent. It uses OpenAI's Whisper model for transcription and translation to Egnlish, OpenAI's GPT-3 for translation to the target language, and different TTS engines for the final speech output.\n",
    "\n",
    "The first version uses the following TTS engines:\n",
    " - Tacotron2 for spectrogram generation\n",
    " - Vocoder/HifiGAN for audio generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "\n",
    "import whisper\n",
    "from speechbrain.pretrained import Tacotron2\n",
    "from speechbrain.pretrained import HIFIGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_model = whisper.load_model(\"small\", download_root=\"../models/whisper_small\")\n",
    "\n",
    "tacotron2 = Tacotron2.from_hparams(source=\"speechbrain/tts-tacotron2-ljspeech\", savedir=\"../models/tts\")\n",
    "hifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-ljspeech\", savedir=\"../models/vocoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def record_buffer(buffer, **kwargs):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    event = asyncio.Event()\n",
    "    idx = 0\n",
    "\n",
    "    def callback(indata, frame_count, time_info, status):\n",
    "        nonlocal idx\n",
    "        if status:\n",
    "            print(status)\n",
    "        remainder = len(buffer) - idx\n",
    "        if remainder == 0:\n",
    "            loop.call_soon_threadsafe(event.set)\n",
    "            raise sd.CallbackStop\n",
    "        indata = indata[:remainder]\n",
    "        buffer[idx:idx + len(indata)] = indata\n",
    "        idx += len(indata)\n",
    "\n",
    "    stream = sd.InputStream(callback=callback, dtype=buffer.dtype,\n",
    "                            channels=buffer.shape[1], **kwargs)\n",
    "    with stream:\n",
    "        await event.wait()\n",
    "\n",
    "\n",
    "def transcribe_and_speak(buffer, **kwargs):\n",
    "    \"\"\"Take the input buffer, transcribe and translate using Whisper and convert back to audio via TTS models\n",
    "\n",
    "    Args:\n",
    "        buffer (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    result = transcription_model.transcribe(buffer.flatten(),\n",
    "                    fp16=False,\n",
    "                    task=\"translate\" )\n",
    "    \n",
    "    print(result[\"text\"])\n",
    "    \n",
    "    \n",
    "    # Running the TTS model (text-to-spectrogram)\n",
    "    mel_output, mel_length, alignment = tacotron2.encode_text(\n",
    "        result.get(\"text\", \"Hello World\")\n",
    "    )\n",
    "    \n",
    "    # Running Vocoder (spectrogram-to-waveform)\n",
    "    waveform = hifi_gan.decode_batch(mel_output)\n",
    "    \n",
    "    \n",
    "    return waveform.squeeze(0).permute((1,0)).numpy()\n",
    "    \n",
    "async def play_buffer(buffer, **kwargs):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    event = asyncio.Event()\n",
    "    idx = 0\n",
    "\n",
    "    def callback(outdata, frame_count, time_info, status):\n",
    "        nonlocal idx\n",
    "        if status:\n",
    "            print(status)\n",
    "        remainder = len(buffer) - idx\n",
    "        if remainder == 0:\n",
    "            loop.call_soon_threadsafe(event.set)\n",
    "            raise sd.CallbackStop\n",
    "        valid_frames = frame_count if remainder >= frame_count else remainder\n",
    "        outdata[:valid_frames] = buffer[idx:idx + valid_frames]\n",
    "        outdata[valid_frames:] = 0\n",
    "        idx += valid_frames\n",
    "\n",
    "    stream = sd.OutputStream(callback=callback, dtype=buffer.dtype,\n",
    "                             channels=buffer.shape[1], **kwargs)\n",
    "    with stream:\n",
    "        await event.wait()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = 22050 * 5\n",
    "channels = 1\n",
    "dtype = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110250, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer = np.zeros((frames, channels), dtype=dtype)\n",
    "buffer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Translating...\n",
      " And what is this? A very good thing?\n",
      "Re-playing...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording...\")\n",
    "await record_buffer(buffer, samplerate=22050, blocksize=1024)\n",
    "\n",
    "print(\"Translating...\")\n",
    "waveform = transcribe_and_speak(buffer)\n",
    "\n",
    "print(\"Re-playing...\")\n",
    "await play_buffer(waveform, samplerate=22050)\n",
    "\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "505538a42fd46471b9db6090de5ab2796e3d9fdf6fd273705b5951e86929a9f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
